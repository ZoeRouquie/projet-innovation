{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"donnees_finales_2.xlsx - Sheet1.csv\")\n",
    "data = data.drop(columns=['idstd'])\n",
    "\n",
    "# Normalisation de la colonne 'anciennete'\n",
    "scaler = StandardScaler()\n",
    "if 'anciennete' in data.columns:\n",
    "    data['anciennete'] = scaler.fit_transform(data[['anciennete']])\n",
    "\n",
    "data['colab_info'] = data['collaboration'] * data['informatique']\n",
    "data['colab_RD'] = data['collaboration'] * data['recherche_developpement']\n",
    "data['info_RD'] = data['informatique'] * data['recherche_developpement']\n",
    "data['colab_info_RD'] = data['collaboration'] * data['informatique'] * data['recherche_developpement']\n",
    "\n",
    "\n",
    "# Filtrer les données pour le pays Inde\n",
    "data_inde = data.loc[data['pays'] == 'India']\n",
    "data =  data.drop(columns=['pays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idées:\n",
    "- variable = regression poisson\n",
    "- variable comptage * ancienneté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['innovation_produits_services','innovation_procedes','innovation_organisation',\n",
    "              'innovation_marketing','innovation','innovation_comptage'])\n",
    "X_inde = data_inde.drop(columns=['innovation_produits_services','innovation_procedes','innovation_organisation',\n",
    "              'innovation_marketing','innovation','innovation_comptage', 'pays_NE','pays_BA','pays_IN','pays_PA','pays'])\n",
    "y_bin = data['innovation']\n",
    "y_cpt = data['innovation_comptage']\n",
    "\n",
    "y_inde_bin = data_inde['innovation']\n",
    "y_inde_cpt = data_inde['innovation_comptage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Variable        VIF\n",
      "0              informatique   4.307612\n",
      "1   recherche_developpement   1.766147\n",
      "2             collaboration   9.449537\n",
      "3          secteur_services   1.283822\n",
      "4          secteur_produits   7.213595\n",
      "5                anciennete   1.032996\n",
      "6              taille_grand  25.475734\n",
      "7              taille_moyen  32.242931\n",
      "8              taille_petit  29.745044\n",
      "9                   pays_NE  12.573726\n",
      "10                  pays_BA  33.591704\n",
      "11                  pays_IN  87.456474\n",
      "12                  pays_PA  15.502830\n",
      "13               colab_info   9.838058\n",
      "14                 colab_RD   9.526470\n",
      "15                  info_RD   4.662349\n",
      "16            colab_info_RD  10.028439\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculer le VIF pour chaque variable explicative\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beaucoup de variable avec un VIF élevé, il vaut mieux utiliser une penalité Lasso pour résoudre simultanément les problèmes de multicolinéarité et de sélection de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reg poisson avec Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients avec pénalisation Lasso :\n",
      "                   Variable  Coefficient\n",
      "0                 Intercept    -0.000000\n",
      "1              informatique     0.019602\n",
      "2   recherche_developpement     0.287383\n",
      "3             collaboration     0.175361\n",
      "4          secteur_services    -0.047636\n",
      "5          secteur_produits    -0.000000\n",
      "6                anciennete    -0.001421\n",
      "7              taille_grand     0.049869\n",
      "8              taille_moyen    -0.000000\n",
      "9              taille_petit    -0.182307\n",
      "10                  pays_NE     0.000000\n",
      "11                  pays_BA     0.330601\n",
      "12                  pays_IN     0.301095\n",
      "13                  pays_PA    -0.324973\n",
      "14               colab_info     0.000000\n",
      "15                 colab_RD     0.000000\n",
      "16                  info_RD    -0.000000\n",
      "17            colab_info_RD     0.000000\n",
      "\n",
      "Résumé du modèle classique (sans pénalisation) :\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5649\n",
      "Model:                            GLM   Df Residuals:                     5639\n",
      "Model Family:                 Poisson   Df Model:                            9\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -8527.0\n",
      "Date:                Fri, 03 Jan 2025   Deviance:                       2219.0\n",
      "Time:                        22:24:02   Pearson chi2:                 1.92e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.2301\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       0.3939      0.043      9.074      0.000       0.309       0.479\n",
      "recherche_developpement     0.2891      0.024     12.048      0.000       0.242       0.336\n",
      "collaboration               0.1896      0.023      8.410      0.000       0.145       0.234\n",
      "secteur_services           -0.0623      0.022     -2.805      0.005      -0.106      -0.019\n",
      "anciennete                 -0.0079      0.009     -0.924      0.356      -0.025       0.009\n",
      "taille_grand                0.0629      0.020      3.088      0.002       0.023       0.103\n",
      "taille_petit               -0.1886      0.022     -8.635      0.000      -0.231      -0.146\n",
      "pays_BA                     0.4137      0.043      9.604      0.000       0.329       0.498\n",
      "pays_IN                     0.3729      0.040      9.380      0.000       0.295       0.451\n",
      "pays_PA                    -0.3278      0.052     -6.259      0.000      -0.430      -0.225\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zoero\\OneDrive\\Bureau\\M2\\S1\\innovation\\projet\\.venv\\Lib\\site-packages\\pyglmnet\\pyglmnet.py:863: UserWarning: Reached max number of iterations without convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyglmnet import GLM\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Étape 1 : Gestion de la colinéarité avec Lasso (pyglmnet)\n",
    "# Préparation des données\n",
    "X2 = data.drop(columns=['innovation_produits_services', 'innovation_procedes', \n",
    "                        'innovation_organisation', 'innovation_marketing', \n",
    "                        'innovation', 'innovation_comptage']).values\n",
    "y_cpt2 = data['innovation_comptage'].values\n",
    "\n",
    "# Ajouter une constante pour inclure un intercept\n",
    "X2_with_const = np.hstack((np.ones((X2.shape[0], 1)), X2))\n",
    "\n",
    "# Modèle de Poisson avec pénalisation L1 (Lasso)\n",
    "glm = GLM(distr='poisson', alpha=1.0, reg_lambda=0.002)\n",
    "glm.fit(X2_with_const, y_cpt2)\n",
    "\n",
    "# Affichage des coefficients\n",
    "columns = ['Intercept'] + list(X.columns)\n",
    "coefficients_lasso = pd.DataFrame({\n",
    "    'Variable': columns,\n",
    "    'Coefficient': glm.beta_\n",
    "})\n",
    "print(\"Coefficients avec pénalisation Lasso :\")\n",
    "print(coefficients_lasso)\n",
    "\n",
    "# Étape 2 : Modèle classique sans pénalisation pour significativité (statsmodels)\n",
    "# Ré-ajuster un modèle Poisson sans pénalisation sur les variables sélectionnées\n",
    "selected_features = coefficients_lasso[coefficients_lasso['Coefficient'] != 0]['Variable']\n",
    "X_selected = data[selected_features[1:]]  # Exclure l'intercept\n",
    "X_selected_const = sm.add_constant(X_selected)\n",
    "\n",
    "# Ajuster un modèle Poisson sans pénalisation\n",
    "poisson_model = sm.GLM(y_cpt2, X_selected_const, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Résumé des résultats\n",
    "print(\"\\nRésumé du modèle classique (sans pénalisation) :\")\n",
    "print(poisson_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients avec pénalisation Lasso :\n",
      "                   Variable  Coefficient\n",
      "0                 Intercept    -0.000000\n",
      "1              informatique    -0.000000\n",
      "2   recherche_developpement     0.156081\n",
      "3             collaboration     0.155468\n",
      "4          secteur_services    -0.061215\n",
      "5          secteur_produits    -0.000000\n",
      "6                anciennete    -0.020299\n",
      "7              taille_grand     0.070150\n",
      "8              taille_moyen    -0.000000\n",
      "9              taille_petit    -0.204231\n",
      "10               colab_info     0.000000\n",
      "11                 colab_RD    -0.000000\n",
      "12                  info_RD     0.002559\n",
      "13            colab_info_RD     0.000000\n",
      "\n",
      "Résumé du modèle classique (sans pénalisation) :\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3492\n",
      "Model:                            GLM   Df Residuals:                     3485\n",
      "Model Family:                 Poisson   Df Model:                            6\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -5439.0\n",
      "Date:                Fri, 03 Jan 2025   Deviance:                       975.72\n",
      "Time:                        22:25:44   Pearson chi2:                     879.\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.07199\n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                1.0107      0.018     57.220      0.000       0.976       1.045\n",
      "collaboration        0.1690      0.026      6.606      0.000       0.119       0.219\n",
      "secteur_services    -0.1045      0.026     -4.020      0.000      -0.155      -0.054\n",
      "anciennete          -0.0259      0.010     -2.489      0.013      -0.046      -0.005\n",
      "taille_grand         0.0834      0.024      3.440      0.001       0.036       0.131\n",
      "taille_petit        -0.2266      0.027     -8.328      0.000      -0.280      -0.173\n",
      "info_RD              0.0571      0.025      2.299      0.022       0.008       0.106\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Préparation des données : convertir DataFrame et Series en ndarray\n",
    "X_inde2 = data_inde.drop(columns=['innovation_produits_services','innovation_procedes','innovation_organisation',\n",
    "              'innovation_marketing','innovation','innovation_comptage', 'pays_NE','pays_BA','pays_IN','pays_PA','pays']).values\n",
    "y_inde_cpt2 = data_inde['innovation_comptage'].values  # Convertir en ndarray\n",
    "\n",
    "\n",
    "# Ajouter une constante pour inclure un intercept\n",
    "X_inde2_with_const = np.hstack((np.ones((X_inde2.shape[0], 1)), X_inde2))\n",
    "\n",
    "# Modèle de Poisson avec pénalisation L1 (Lasso)\n",
    "glm = GLM(distr='poisson', alpha=1.0, reg_lambda=0.002)\n",
    "glm.fit(X_inde2_with_const, y_inde_cpt2)\n",
    "\n",
    "# Affichage des coefficients\n",
    "columns = ['Intercept'] + list(X_inde.columns)\n",
    "coefficients_lasso = pd.DataFrame({\n",
    "    'Variable': columns,\n",
    "    'Coefficient': glm.beta_\n",
    "})\n",
    "print(\"Coefficients avec pénalisation Lasso :\")\n",
    "print(coefficients_lasso)\n",
    "\n",
    "# Étape 2 : Modèle classique sans pénalisation pour significativité (statsmodels)\n",
    "# Ré-ajuster un modèle Poisson sans pénalisation sur les variables sélectionnées\n",
    "selected_features = coefficients_lasso[coefficients_lasso['Coefficient'] != 0]['Variable']\n",
    "X_selected = data_inde[selected_features[1:]]  # Exclure l'intercept\n",
    "X_selected_const = sm.add_constant(X_selected)\n",
    "\n",
    "# Ajuster un modèle Poisson sans pénalisation\n",
    "poisson_model = sm.GLM(y_inde_cpt2, X_selected_const, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Résumé des résultats\n",
    "print(\"\\nRésumé du modèle classique (sans pénalisation) :\")\n",
    "print(poisson_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taux de diversité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bis = y_cpt * data['anciennete']\n",
    "y_bis_inde = y_inde_cpt * data_inde['anciennete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients avec pénalisation Lasso :\n",
      "                   Variable  Coefficient\n",
      "0              informatique    -0.057853\n",
      "1   recherche_developpement    -0.051164\n",
      "2             collaboration    -0.000000\n",
      "3          secteur_services     0.006130\n",
      "4          secteur_produits     0.066070\n",
      "5                anciennete     2.447283\n",
      "6              taille_grand    -0.000000\n",
      "7              taille_moyen    -0.006495\n",
      "8              taille_petit     0.004161\n",
      "9                   pays_NE     0.080681\n",
      "10                  pays_BA    -0.044681\n",
      "11                  pays_IN    -0.000000\n",
      "12                  pays_PA     0.141908\n",
      "13               colab_info    -0.024517\n",
      "14                 colab_RD    -0.000000\n",
      "15                  info_RD     0.081872\n",
      "16            colab_info_RD     0.014223\n",
      "\n",
      "Résumé du modèle classique (sans pénalisation) :\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.837\n",
      "Method:                 Least Squares   F-statistic:                     2233.\n",
      "Date:                Fri, 03 Jan 2025   Prob (F-statistic):               0.00\n",
      "Time:                        23:02:33   Log-Likelihood:                -8430.2\n",
      "No. Observations:                5649   AIC:                         1.689e+04\n",
      "Df Residuals:                    5635   BIC:                         1.698e+04\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       0.0619      0.049      1.268      0.205      -0.034       0.158\n",
      "informatique               -0.1690      0.070     -2.407      0.016      -0.307      -0.031\n",
      "recherche_developpement    -0.1289      0.041     -3.156      0.002      -0.209      -0.049\n",
      "secteur_services            0.0308      0.039      0.791      0.429      -0.046       0.107\n",
      "secteur_produits            0.2663      0.107      2.479      0.013       0.056       0.477\n",
      "anciennete                  2.4503      0.015    168.272      0.000       2.422       2.479\n",
      "taille_moyen               -0.0141      0.037     -0.386      0.700      -0.086       0.058\n",
      "taille_petit                0.0115      0.040      0.292      0.770      -0.066       0.089\n",
      "pays_NE                     0.2913      0.056      5.227      0.000       0.182       0.401\n",
      "pays_BA                    -0.1920      0.100     -1.918      0.055      -0.388       0.004\n",
      "pays_PA                     0.4333      0.048      8.943      0.000       0.338       0.528\n",
      "colab_info                 -0.2397      0.201     -1.195      0.232      -0.633       0.153\n",
      "info_RD                     0.2546      0.082      3.095      0.002       0.093       0.416\n",
      "colab_info_RD               0.2022      0.219      0.923      0.356      -0.227       0.632\n",
      "==============================================================================\n",
      "Omnibus:                      766.599   Durbin-Watson:                   1.816\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10177.529\n",
      "Skew:                           0.050   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.575   Cond. No.                         29.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Étape 1 : Ajustement avec Lasso pour gérer la multicolinéarité et sélectionner les variables\n",
    "lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=0.002))  # Ajustez alpha selon vos besoins\n",
    "lasso_model.fit(X, y_bis)\n",
    "\n",
    "# Récupérer les coefficients après Lasso\n",
    "coefficients = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Coefficient': lasso_model.named_steps['lasso'].coef_\n",
    "})\n",
    "print(\"Coefficients avec pénalisation Lasso :\")\n",
    "print(coefficients)\n",
    "\n",
    "# Étape 2 : Sélection des variables non nulles\n",
    "selected_features = coefficients[coefficients['Coefficient'] != 0]['Variable']\n",
    "\n",
    "# Étape 3 : Analyse classique avec statsmodels pour tester la significativité des variables sélectionnées\n",
    "X_selected = X[selected_features]  # Conserver uniquement les variables sélectionnées\n",
    "X_selected_const = sm.add_constant(X_selected)  # Ajouter une constante pour l'intercept\n",
    "\n",
    "# Ajuster un modèle de régression linéaire classique\n",
    "model = sm.OLS(y_bis, X_selected_const).fit()\n",
    "\n",
    "# Résumé des résultats\n",
    "print(\"\\nRésumé du modèle classique (sans pénalisation) :\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients avec pénalisation Lasso :\n",
      "                   Variable  Coefficient\n",
      "0              informatique     0.032484\n",
      "1   recherche_developpement     0.010543\n",
      "2             collaboration     0.014731\n",
      "3          secteur_services     0.020232\n",
      "4          secteur_produits     0.000000\n",
      "5                anciennete     2.690180\n",
      "6              taille_grand     0.018035\n",
      "7              taille_moyen    -0.000000\n",
      "8              taille_petit    -0.000000\n",
      "9                colab_info    -0.054066\n",
      "10                 colab_RD    -0.021455\n",
      "11                  info_RD    -0.000000\n",
      "12            colab_info_RD     0.051751\n",
      "\n",
      "Résumé du modèle classique (sans pénalisation) :\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.886\n",
      "Model:                            OLS   Adj. R-squared:                  0.886\n",
      "Method:                 Least Squares   F-statistic:                     3003.\n",
      "Date:                Fri, 03 Jan 2025   Prob (F-statistic):               0.00\n",
      "Time:                        23:04:34   Log-Likelihood:                -4836.8\n",
      "No. Observations:                3492   AIC:                             9694.\n",
      "Df Residuals:                    3482   BIC:                             9755.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -0.1181      0.044     -2.671      0.008      -0.205      -0.031\n",
      "informatique                0.0818      0.042      1.967      0.049       0.000       0.163\n",
      "recherche_developpement     0.0447      0.046      0.978      0.328      -0.045       0.134\n",
      "collaboration               0.1718      0.122      1.411      0.158      -0.067       0.411\n",
      "secteur_services            0.0566      0.041      1.381      0.167      -0.024       0.137\n",
      "anciennete                  2.6547      0.016    161.696      0.000       2.622       2.687\n",
      "taille_grand                0.0414      0.039      1.069      0.285      -0.035       0.117\n",
      "colab_info                 -0.4794      0.222     -2.159      0.031      -0.915      -0.044\n",
      "colab_RD                   -0.2024      0.131     -1.539      0.124      -0.460       0.055\n",
      "colab_info_RD               0.4968      0.237      2.097      0.036       0.032       0.961\n",
      "==============================================================================\n",
      "Omnibus:                      720.135   Durbin-Watson:                   1.855\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13714.655\n",
      "Skew:                          -0.463   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.665   Cond. No.                         28.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=0.002))  # Ajustez alpha selon vos besoins\n",
    "lasso_model.fit(X_inde, y_bis_inde)\n",
    "\n",
    "# Récupérer les coefficients après Lasso\n",
    "coefficients = pd.DataFrame({\n",
    "    'Variable': X_inde.columns,\n",
    "    'Coefficient': lasso_model.named_steps['lasso'].coef_\n",
    "})\n",
    "print(\"Coefficients avec pénalisation Lasso :\")\n",
    "print(coefficients)\n",
    "\n",
    "# Étape 2 : Sélection des variables non nulles\n",
    "selected_features = coefficients[coefficients['Coefficient'] != 0]['Variable']\n",
    "\n",
    "# Étape 3 : Analyse classique avec statsmodels pour tester la significativité des variables sélectionnées\n",
    "X_selected = X_inde[selected_features]  # Conserver uniquement les variables sélectionnées\n",
    "X_selected_const = sm.add_constant(X_selected)  # Ajouter une constante pour l'intercept\n",
    "\n",
    "# Ajuster un modèle de régression linéaire classique\n",
    "model = sm.OLS(y_bis_inde, X_selected_const).fit()\n",
    "\n",
    "# Résumé des résultats\n",
    "print(\"\\nRésumé du modèle classique (sans pénalisation) :\")\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
